# ğŸ¨ DF-GAN: Deep-Fusion Generative Adversarial Network
### *Transform Text into Stunning Images* âœ¨

<div align="center">

![Version](https://img.shields.io/badge/version-1.0.0-blue.svg)
![PyTorch](https://img.shields.io/badge/PyTorch-2.5-orange.svg)
![Python](https://img.shields.io/badge/Python-3.9-green.svg)
![CUDA](https://img.shields.io/badge/CUDA-Enabled-brightgreen.svg)

</div>

---

## ğŸ“– Overview

**DF-GAN** is a powerful text-to-image synthesis model that generates high-quality **256Ã—256** images directly from natural language descriptions. This repository provides everything you need: dataset preparation, DAMSM encoders, training scripts, sampling utilities, and comprehensive evaluation pipelines.

> ğŸ’¡ **Key Features:** Simple architecture, powerful results, FID evaluation, and optional CLIP alignment scoring

---

## ğŸš€ Getting Started

### ğŸ“¦ Dataset Preparation

Follow these steps to set up your datasets:

#### 1ï¸âƒ£ **Download Preprocessed Metadata**
- ğŸ¦ [**Birds Dataset**](https://drive.google.com/file/d/1I6ybkR7L64K8hZOraEZDuHh0cCJw5OUj/view?usp=sharing) â†’ Extract to `data/`
- ğŸ–¼ï¸ [**COCO Dataset**](https://drive.google.com/file/d/15Fw-gErCEArOFykW3YTnLKpRcPgI_3AB/view?usp=sharing) â†’ Extract to `data/`

#### 2ï¸âƒ£ **Download Image Data**
- ğŸ¦ [**Birds Images**](http://www.vision.caltech.edu/visipedia/CUB-200-2011.html) â†’ Extract to `data/birds/`
- ğŸ–¼ï¸ [**COCO2014 Images**](http://cocodataset.org/#download) â†’ Extract to `data/coco/images/`

---

## ğŸ—ï¸ Model Architecture

### ğŸ”„ Input Pipeline

| Component | Description |
|-----------|-------------|
| ğŸ“ **Text Prompts** | Tokenized via DAMSM vocabulary |
| ğŸ² **Noise Vector (z)** | `z_dim = 100`, batch size = 20, truncation = 0.88 |
| ğŸ”¤ **DAMSM Encoders** | Text encoder + Image encoder |

### ğŸ¯ Output Pipeline

| Output Type | Details |
|-------------|---------|
| ğŸ–¼ï¸ **Generated Images** | PNG format, normalized from [-1, 1] â†’ [0, 255] |
| ğŸ’¾ **Checkpoints** | Periodic saves in `saved_models/` |
| ğŸ“Š **Evaluation Metrics** | FID scores & CLIP alignment (optional) |

---

## âš™ï¸ Key Components

### ğŸ§  1. Text Encoder
- **Architecture:** Bi-LSTM  
- **Output:** 256-dim word embeddings + 256-dim sentence embeddings  
- **Purpose:** Converts text descriptions into semantic vectors

### ğŸ–¼ï¸ 2. Image Encoder
- **Backbone:** Inception v3  
- **Output:** 256-dim image embeddings  
- **Purpose:** Projects images into shared embedding space

### ğŸ¨ 3. Generator Network
ğŸ“¥ Input (z) â†’ ğŸ”„ FC Layer â†’ ğŸ“ˆ 8Â·nfÂ·4Ã—4 â†’ ğŸ” G_Blocks (upsampling) â†’ ğŸ¨ RGB â†’ âœ… Tanh <br>

**Text Conditioning Features:**
- âœ¨ DFBLK + Affine modulation
- ğŸ”— Concatenates [z, sentence embedding]
- ğŸ›ï¸ Affine-modulates feature maps in each block

### ğŸ›¡ï¸ 4. Discriminator Network

#### **NetD (Image Discriminator)**
- ğŸŒ Multi-scale CNN architecture
- ğŸ“‰ Downsampling via D_Block modules

#### **NetC (Conditional Discriminator)**
- ğŸ”€ Combines image features + sentence embeddings
- âœ”ï¸ Outputs conditional real/fake logits

#### **Training Stabilization**
| Technique | Purpose |
|-----------|---------|
| âš–ï¸ **Hinge Loss** | Stable adversarial training |
| âŒ **Mismatched Negatives** | Better text-image alignment |
| ğŸ¯ **MAGP** | Matching-Aware Gradient Penalty |
| ğŸ“Š **EMA** | Exponential Moving Average for stable sampling |

---

## ğŸ“Š Evaluation Metrics

### ğŸ“ˆ FrÃ©chet Inception Distance (FID)
- Uses 2048-dim InceptionV3 features
- Compares generated images to dataset `.npz` statistics
- **Lower is better** â¬‡ï¸

### ğŸ¤ CLIP Alignment (Optional)
- Generates text-to-image sample grids
- Computes cosine similarity via CLIP ViT-B/32
- Results saved in `alignment_samples/`

---

## ğŸ“ Training

### ğŸ’» Environment Setup

| Component | Specification |
|-----------|---------------|
| ğŸ **Python** | 3.9 |
| ğŸ”¥ **PyTorch** | 2.5 with CUDA |
| ğŸ® **GPU** | NVIDIA GeForce RTX 4070 (12GB VRAM) |

### ğŸƒ Start Training

Navigate to the code directory:
```bash
cd DF-GAN/code/
```

#### ğŸ¦ **For Birds Dataset:**
```bash
scripts/train.bat ./cfg/bird.yml
```

#### ğŸ–¼ï¸ **For COCO Dataset:**
```bash
scripts/train.bat ./cfg/coco.yml
```

### ğŸ”„ Resume Training

If training is interrupted, configure these parameters in `train.bat`:
- `resume_epoch` â†’ Epoch number to resume from
- `resume_model_path` â†’ Path to checkpoint file

### ğŸ’¡ Pro Tips

> âš ï¸ **Note:** Our evaluation codes don't save synthesized images by default (~30,000 images).  
> To save them, set `save_image: True` in your YAML configuration file.

---

## ğŸ† Performance Benchmarks

<div align="center">

| ğŸ—‚ï¸ Dataset | ğŸ“Š FID Score â¬‡ï¸ | â±ï¸ Epochs |
|------------|----------------|----------|
| ğŸ¦ **CUB (Birds)** | **24.71** | 230 |
| ğŸ–¼ï¸ **MS-COCO** | **15.4** | 290 |

</div>

---

## ğŸ¨ Image Sampling

### ğŸ–¼ï¸ Generate Images from Text

1ï¸âƒ£ **Navigate to code directory:**
```bash
cd DF-GAN/code/
```

2ï¸âƒ£ **Prepare your text descriptions:**
- Edit `./code/example_captions/dataset_name.txt`
- Add your custom captions (one per line)

3ï¸âƒ£ **Run sampling:**

#### ğŸ¦ **For Birds:**
```bash
 python src/sample.py --cfg cfg/bird.yml
```

#### ğŸ–¼ï¸ **For COCO:**
```bash
 python src/sample.py --cfg cfg/coco.yml
```

### ğŸ“ Output Location
Generated images are saved in: `./code/samples/`

---


## ğŸ“„ License

This project is released under the MIT License.

---

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

---

## ğŸ“§ Contact

For questions and feedback:
- ğŸ“® Open an issue on GitHub
- ğŸ’¬ Join our community discussions

---

<div align="center">

### â­ If you find this project useful, please consider giving it a star! â­

**Made with â¤ï¸ by the GANners Team**

</div>

